import streamlit as st
import requests
import pandas as pd
import math
import random
from streamlit_js_eval import get_geolocation
from geopy.geocoders import Nominatim
from datetime import datetime
import time

st.set_page_config(page_title="eBird Israel Ultimate Pro", layout="wide")

class eBirdEngine:
    def __init__(self, api_key):
        self.api_key = api_key
        self.headers = {"X-eBirdApiToken": api_key}
        self.base_url = "https://api.ebird.org/v2"
        self.checklist_cache = {}  # ××˜××•×Ÿ ×œ×“×™×•×•×—×™× ××œ××™×

    def calculate_distance(self, lat1, lon1, lat2, lon2):
        R = 6371
        dlat, dlon = math.radians(lat2-lat1), math.radians(lon2-lon1)
        a = math.sin(dlat/2)**2 + math.cos(math.radians(lat1))*math.cos(math.radians(lat2))*math.sin(dlon/2)**2
        return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))

    def get_checklist_details(self, sub_id):
        """×©×•×œ×£ ×“×™×•×•×— ××œ× ×¢× ×›×œ ×”××™× ×™× ×©×‘×•"""
        if sub_id in self.checklist_cache:
            return self.checklist_cache[sub_id]
        
        try:
            url = f"{self.base_url}/product/checklist/view/{sub_id}"
            response = requests.get(url, headers=self.headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                self.checklist_cache[sub_id] = data
                return data
            time.sleep(0.1)  # ×œ×× ×•×¢ ×—×¡×™××” ××”-API
        except Exception as e:
            st.warning(f"×©×’×™××” ×‘×©×œ×™×¤×ª ×“×™×•×•×— {sub_id}: {e}")
        return None

    def fetch_comprehensive_data(self, lat, lon, dist, days, progress_bar=None):
        """×©×•××‘ × ×ª×•× ×™× ×•××– ××©×œ×™× ×¢× ×“×™×•×•×—×™× ××œ××™×"""
        all_data = []
        
        base_params = {
            "lat": lat, 
            "lng": lon, 
            "dist": dist, 
            "back": days, 
            "fmt": "json", 
            "includeProvisional": "true",
            "maxResults": 10000
        }
        
        # ×©×œ×‘ 1: ×©×œ×™×¤×ª ×ª×¦×¤×™×•×ª ×‘×¡×™×¡×™×•×ª
        endpoints = [
            ("×ª×¦×¤×™×•×ª ×¨×’×™×œ×•×ª", f"{self.base_url}/data/obs/geo/recent"),
            ("×ª×¦×¤×™×•×ª ×¨××•×™×•×ª ×œ×¦×™×•×Ÿ", f"{self.base_url}/data/obs/geo/recent/notable"),
        ]
        
        for idx, (name, url) in enumerate(endpoints):
            try:
                if progress_bar:
                    progress_bar.progress((idx + 1) / (len(endpoints) + 1), f"×©×•×œ×£ {name}...")
                response = requests.get(url, headers=self.headers, params=base_params, timeout=30)
                if response.status_code == 200:
                    all_data.extend(response.json())
            except Exception as e:
                st.warning(f"×©×’×™××” ×‘×˜×¢×™× ×ª {name}: {e}")
        
        if not all_data:
            return pd.DataFrame(), {}
        
        # ×”××¨×” ×œ-DataFrame
        df = pd.DataFrame(all_data)
        df = df.drop_duplicates(subset=['subId', 'sciName'], keep='first')
        
        # ×©×œ×‘ 2: ×©×œ×™×¤×ª ×“×™×•×•×—×™× ××œ××™×
        unique_subs = df['subId'].unique()
        if progress_bar:
            progress_bar.progress(0.7, f"×©×•×œ×£ {len(unique_subs)} ×“×™×•×•×—×™× ××œ××™×...")
        
        checklist_species_count = {}
        
        for idx, sub_id in enumerate(unique_subs[:100]):  # ××’×‘×œ×” ×©×œ 100 ×“×™×•×•×—×™×
            if idx % 10 == 0 and progress_bar:
                progress_bar.progress(0.7 + (idx / len(unique_subs[:100])) * 0.3, 
                                    f"×¢×™×‘×•×“ ×“×™×•×•×— {idx + 1}/{min(len(unique_subs), 100)}...")
            
            checklist = self.get_checklist_details(sub_id)
            if checklist and 'obs' in checklist:
                # ×¡×¤×™×¨×ª ××™× ×™× ×™×™×—×•×“×™×™× ×‘×“×™×•×•×—
                species_in_checklist = set()
                for obs in checklist['obs']:
                    if 'sciName' in obs:
                        species_in_checklist.add(obs['sciName'])
                checklist_species_count[sub_id] = len(species_in_checklist)
        
        return df, checklist_species_count

def load_birds_data():
    """×˜×•×¢×Ÿ ××ª ×¨×©×™××ª ×”×¦×™×¤×•×¨×•×ª ××”×§×•×‘×¥ birds.json"""
    import os
    import json
    
    # × ×ª×™×‘×™× ××¤×©×¨×™×™× ×œ×§×•×‘×¥
    possible_paths = [
        "/mnt/user-data/uploads/birds.json",  # ×§×•×‘×¥ ×©×”×•×¢×œ×”
        "./birds.json",  # ×‘×ª×™×§×™×™×” ×”× ×•×›×—×™×ª
        "birds.json"  # ×‘×ª×™×§×™×™×ª ×”×¢×‘×•×“×”
    ]
    
    # × ×™×¡×™×•×Ÿ ×œ×˜×¢×•×Ÿ ××›×œ × ×ª×™×‘ ××¤×©×¨×™
    for path in possible_paths:
        if os.path.exists(path):
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    birds_data = json.load(f)
                st.success(f"âœ… × ×˜×¢×Ÿ ×§×•×‘×¥ ×¦×™×¤×•×¨×™× ×: {path}")
                return birds_data
            except Exception as e:
                st.warning(f"×©×’×™××” ×‘×§×¨×™××ª {path}: {e}")
    
    # ×× ×œ× × ××¦× - × ×™×¡×™×•×Ÿ ×œ×˜×¢×•×Ÿ ×-birds_data.py
    try:
        from birds_data import ALL_BIRDS
        st.info("× ×˜×¢×Ÿ ××§×•×‘×¥ birds_data.py")
        return ALL_BIRDS
    except (ImportError, ModuleNotFoundError):
        pass
    
    # ×‘×“×™×§×” ×›×œ×œ×™×ª ×©×œ ×›×œ ×”×§×‘×¦×™× ×‘×ª×™×§×™×™×ª uploads
    upload_dir = "/mnt/user-data/uploads"
    if os.path.exists(upload_dir):
        files = os.listdir(upload_dir)
        
        # ×—×™×¤×•×© ×›×œ ×§×•×‘×¥ JSON
        json_files = [f for f in files if f.endswith('.json')]
        if json_files:
            try:
                with open(os.path.join(upload_dir, json_files[0]), 'r', encoding='utf-8') as f:
                    birds_data = json.load(f)
                st.success(f"âœ… × ×˜×¢×Ÿ ×§×•×‘×¥: {json_files[0]}")
                return birds_data
            except Exception as e:
                st.warning(f"×©×’×™××” ×‘×§×¨×™××ª JSON: {e}")
        
        # ×—×™×¤×•×© ×§×‘×¦×™ CSV
        csv_files = [f for f in files if f.endswith('.csv')]
        if csv_files:
            try:
                df = pd.read_csv(os.path.join(upload_dir, csv_files[0]))
                birds = []
                for _, row in df.iterrows():
                    birds.append({
                        "heb": row.get('heb', row.get('hebrew', row.get('×©× ×¢×‘×¨×™', 'Unknown'))),
                        "eng": row.get('eng', row.get('english', row.get('×©× ×× ×’×œ×™', 'Unknown'))),
                        "sci": row.get('sci', row.get('scientific', row.get('×©× ××“×¢×™', '')))
                    })
                st.success(f"âœ… × ×˜×¢×Ÿ ×§×•×‘×¥ CSV: {csv_files[0]}")
                return birds
            except Exception as e:
                st.warning(f"×©×’×™××” ×‘×§×¨×™××ª CSV: {e}")
    
    # ×¨×©×™××” ×‘×¡×™×¡×™×ª ×›×‘×¨×™×¨×ª ××—×“×œ
    st.error("âŒ ×œ× × ××¦× ×§×•×‘×¥ birds.json - ×”×¢×œ×” ××ª ×”×§×•×‘×¥ ××• ×©×™× ××•×ª×• ×‘××•×ª×” ×ª×™×§×™×™×”")
    st.info("ğŸ’¡ ×”×§×•×‘×¥ ×¦×¨×™×š ×œ×”×™×•×ª ×‘×¨×©×™××” ×©×œ ××•×‘×™×™×§×˜×™× ×¢× ×”××¤×ª×—×•×ª: heb, eng, sci")
    return [
        {"heb": "×“×¨×•×¨ ×”×‘×™×ª", "eng": "House Sparrow", "sci": "Passer domesticus"},
        {"heb": "×‘×•×œ×‘×•×œ", "eng": "Common Bulbul", "sci": "Pycnonotus barbatus"},
        {"heb": "×¢×•×¨×‘ ××¦×•×™", "eng": "Hooded Crow", "sci": "Corvus cornix"},
    ]

st.title("ğŸ‡®ğŸ‡± ×¦×¤×¨×•×ª ×™×©×¨××œ - ×’×¨×¡×ª ×”×“×™×•×•×—×™× ×”××œ××™×")

with st.sidebar:
    st.header("×”×’×“×¨×•×ª")
    api_key = st.text_input("API Key:", type="password")
    
    st.subheader("××™×§×•×")
    mode = st.radio("××¨×›×– ×”×—×™×¤×•×©:", ["×›×¤×¨ ×¡×‘×", "GPS", "×¢×™×¨"])
    clat, clon = 32.175, 34.906
    
    if mode == "GPS":
        loc = get_geolocation()
        if loc: 
            clat, clon = loc['coords']['latitude'], loc['coords']['longitude']
            st.success(f"ğŸ“ {clat:.4f}, {clon:.4f}")
    elif mode == "×¢×™×¨":
        city = st.text_input("×©× ×¢×™×¨:", "Kfar Saba")
        try:
            geo = Nominatim(user_agent=f"ebird_app_{random.randint(1,9999)}").geocode(f"{city}, Israel")
            if geo: 
                clat, clon = geo.latitude, geo.longitude
                st.success(f"ğŸ“ {city}: {clat:.4f}, {clon:.4f}")
        except Exception as e:
            st.error(f"×©×’×™××”: {e}")
    
    st.subheader("×¤×¨××˜×¨×™ ×—×™×¤×•×©")
    radius = st.slider("×¨×“×™×•×¡ (×§\"×):", 1, 50, 50)
    days = st.slider("×™××™× ××—×•×¨×”:", 1, 30, 14)
    
    st.info("ğŸ’¡ ×”×¢×œ×” ×§×•×‘×¥ birds.json ×¢× ×¨×©×™××ª ×”×¦×™×¤×•×¨×•×ª ××• ×©×™× ××•×ª×• ×‘××•×ª×” ×ª×™×§×™×™×”")

if not api_key:
    st.warning("âš ï¸ ×”×–×Ÿ API Key ×-eBird ×œ×”×¤×¢×œ×”")
    st.info("×§×‘×œ API Key ×‘×—×™× × ×: https://ebird.org/api/keygen")
    st.stop()

engine = eBirdEngine(api_key)

if st.button("ğŸš€ ×”×ª×—×œ ×¡×¨×™×§×” ××œ××”", type="primary"):
    progress_bar = st.progress(0, "××ª×—×™×œ ×¡×¨×™×§×”...")
    
    with st.spinner("×©×•××‘ × ×ª×•× ×™×..."):
        df, checklist_counts = engine.fetch_comprehensive_data(clat, clon, radius, days, progress_bar)
        
        if not df.empty:
            # ×—×™×©×•×‘ ××¨×—×§
            df['distance'] = df.apply(
                lambda x: engine.calculate_distance(clat, clon, x['lat'], x['lng']), 
                axis=1
            )
            
            # ×”×•×¡×¤×ª ××™×“×¢ ×¢×œ ×›××•×ª ××™× ×™× ×‘×“×™×•×•×—
            df['checklist_species_count'] = df['subId'].map(checklist_counts)
            
            st.session_state['master_df'] = df
            st.session_state['checklist_counts'] = checklist_counts
            
            progress_bar.progress(1.0, "×”×•×©×œ×!")
            time.sleep(0.5)
            progress_bar.empty()
            
            st.success(f"âœ… × ×˜×¢× ×• {len(df):,} ×ª×¦×¤×™×•×ª ×-{df['locId'].nunique()} ××•×§×“×™× ×•-{len(checklist_counts)} ×“×™×•×•×—×™× ××œ××™×")
        else:
            st.error("âŒ ×œ× ×”×ª×§×‘×œ×• × ×ª×•× ×™×. ×‘×“×•×§ API Key ×•×¤×¨××˜×¨×™×.")
            progress_bar.empty()

if 'master_df' in st.session_state:
    df = st.session_state['master_df']
    checklist_counts = st.session_state.get('checklist_counts', {})
    
    tab1, tab2, tab3 = st.tabs([
        "ğŸ“Š 10 ××•×§×“×™× ×¢×©×™×¨×™×", 
        "ğŸ¯ ×ª×¦×¤×™×•×ª ×©×™× ×œ××™×Ÿ",
        "ğŸ“‹ ×“×™×•×•×—×™× ××¤×•×¨×˜×™×"
    ])

    with tab1:
        st.header("ğŸ† ×”××•×§×“×™× ×¢× ×¢×•×©×¨ ×”××™× ×™× ×”×’×‘×•×” ×‘×™×•×ª×¨")
        
        # ×—×™×©×•×‘ ×××™×ª×™ ×œ×¤×™ ×“×™×•×•×—×™× ××œ××™×
        location_analysis = []
        
        for loc_id, group in df.groupby('locId'):
            loc_name = group.iloc[0]['locName']
            distance = group.iloc[0]['distance']
            
            # ×× ×™×© ×œ× ×• ×“×™×•×•×—×™× ××œ××™× - × ×©×ª××© ×‘×”×
            checklists_at_location = group['subId'].unique()
            max_species_in_checklist = 0
            total_unique_species = group['sciName'].nunique()
            
            for sub_id in checklists_at_location:
                if sub_id in checklist_counts:
                    count = checklist_counts[sub_id]
                    if count > max_species_in_checklist:
                        max_species_in_checklist = count
            
            # × ×©×ª××© ×‘××§×¡×™××•× ×‘×™×Ÿ ×©×ª×™ ×”×©×™×˜×•×ª
            final_count = max(max_species_in_checklist, total_unique_species)
            
            location_analysis.append({
                "××™×§×•×": loc_name,
                "××¨×—×§ (×§\"×)": round(distance, 1),
                "××¡×¤×¨ ××™× ×™×": final_count,
                "×“×™×•×•×—×™×": len(checklists_at_location),
                "×¢×“×›×•×Ÿ ××—×¨×•×Ÿ": group['obsDt'].max()
            })
        
        summary_df = pd.DataFrame(location_analysis)
        top_10 = summary_df.sort_values("××¡×¤×¨ ××™× ×™×", ascending=False).head(10)
        
        st.write(f"**× ×•×ª×—×• {len(summary_df)} ××•×§×“×™×**")
        
        # ×”×•×¡×¤×ª ×¦×‘×¢ ×œ×©×•×¨×•×ª
        st.dataframe(
            top_10.reset_index(drop=True),
            use_container_width=True,
            hide_index=True,
            height=400
        )
        
        # ×’×¨×£
        st.bar_chart(top_10.set_index('××™×§×•×')['××¡×¤×¨ ××™× ×™×'])

    with tab2:
        st.header("ğŸ¯ ×ª×¦×¤×™×•×ª ×©×™× ×œ×¤×™ ××™×Ÿ")
        
        birds_list = load_birds_data()
        bird_map = {
            f"{b.get('heb', 'Unknown')} ({b.get('eng', 'Unknown')})": b.get('sci', '') 
            for b in birds_list
        }
        
        selected_bird = st.selectbox(
            "×‘×—×¨ ×¦×™×¤×•×¨:", 
            [""] + sorted(list(bird_map.keys())),
            key="bird_selector"
        )
        
        if selected_bird:
            target_sci = bird_map.get(selected_bird, "")
            
            if not target_sci:
                st.error("×œ× × ××¦× ×©× ××“×¢×™")
            else:
                matches = df[df['sciName'].str.contains(target_sci, case=False, na=False, regex=False)].copy()
                
                if not matches.empty:
                    matches['sort_qty'] = pd.to_numeric(matches['howMany'], errors='coerce').fillna(1).astype(int)
                    top_10_obs = matches.sort_values("sort_qty", ascending=False).head(10)
                    
                    display_df = top_10_obs[[
                        'locName', 'howMany', 'distance', 'obsDt', 
                        'userDisplayName', 'checklist_species_count'
                    ]].copy()
                    
                    display_df.columns = [
                        '××™×§×•×', '×›××•×ª', '××¨×—×§ (×§\"×)', 
                        '×ª××¨×™×š', '×¦×•×¤×”', '×¡×”"×› ××™× ×™× ×‘×“×™×•×•×—'
                    ]
                    display_df['××¨×—×§ (×§\"×)'] = display_df['××¨×—×§ (×§\"×)'].round(1)
                    
                    st.write(f"**× ××¦××• {len(matches)} ×ª×¦×¤×™×•×ª ×©×œ {selected_bird}**")
                    st.dataframe(
                        display_df.reset_index(drop=True),
                        use_container_width=True,
                        hide_index=True
                    )
                else:
                    st.info(f"×œ× × ××¦××• ×ª×¦×¤×™×•×ª ×©×œ {selected_bird}")

    with tab3:
        st.header("ğŸ“‹ ×¤×™×¨×•×˜ ×“×™×•×•×—×™× ××œ××™×")
        
        if checklist_counts:
            checklist_df_data = []
            for sub_id, count in sorted(checklist_counts.items(), key=lambda x: x[1], reverse=True)[:20]:
                obs_in_checklist = df[df['subId'] == sub_id].iloc[0]
                checklist_df_data.append({
                    "×“×™×•×•×—": sub_id,
                    "××™×§×•×": obs_in_checklist['locName'],
                    "××™× ×™×": count,
                    "×ª××¨×™×š": obs_in_checklist['obsDt'],
                    "×¦×•×¤×”": obs_in_checklist['userDisplayName']
                })
            
            checklist_display = pd.DataFrame(checklist_df_data)
            st.write("**20 ×”×“×™×•×•×—×™× ×”×¢×©×™×¨×™× ×‘×™×•×ª×¨:**")
            st.dataframe(checklist_display, use_container_width=True, hide_index=True)
        else:
            st.info("×œ× × ×˜×¢× ×• ×“×™×•×•×—×™× ××œ××™× ×¢×“×™×™×Ÿ")
